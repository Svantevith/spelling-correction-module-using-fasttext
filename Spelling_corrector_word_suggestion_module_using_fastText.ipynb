{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spelling corrector/word suggestion module using fastText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a spelling correction/word suggestion module\n",
        "**fastText** can be applied to solve a plethora of problems such as **spelling correction, auto\n",
        "suggestions**, and so on since it is based on **sub-word representation**. Datasets such as **user\n",
        "search query, chatbots or conversations, reviews**, and **ratings** can be used to **build fastText\n",
        "models**. We can apply them to **enhance the customer experience** in the future by providing\n",
        "information such as **better suggestions, displaying better products, autocorrecting user\n",
        "input**, and so on. \n",
        "\n",
        "In this notebook I am using a **fastText model** trained on some **comments data** from **[Kaggle's toxic comment classification challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)** to build a **spelling correction/word suggestion** module. By providing some **incorrect spellings** to the built model, we can determine **how well the model\n",
        "does in terms of correcting them**."
      ],
      "metadata": {
        "id": "BOT4GFcxytKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fastText\n",
        "**fastText** is a **word embedding** method that is an **extension of the word2vec model**. Instead of learning vectors for words directly, **fastText** represents each word as an **n-gram of characters**. \n",
        "\n",
        "> For example, take the word, ***artificial*** with *n = 3*, the **fastText** representation of this word is \n",
        ">\n",
        "> [***ar, art, rti, tif, ifi, fic, ici, ial, al***]  \n",
        "\n",
        "This helps capture the **meaning of shorter words** and allows the **embeddings** to understand **suffixes** and **prefixes**. Once the word has been represented using **character n-grams**, a **skip-gram** model is **trained to learn** the **embeddings**. \n",
        "\n",
        "> This model is considered to be a **bag of words** model with a **sliding window over a word** because **no internal structure of the word** is taken into account. As long as the **characters are within this window**, the **order of the n-grams doesn’t matter**.\n",
        "\n",
        "**fastText** works well with **rare words**. So even if a **word wasn’t seen during training**, or in other words, is **not in vocabulary**, it can be **broken down into n-grams to get its embeddings**.\n",
        "\n",
        "**Word2vec** fails to provide any vector representation for **words** that are **not in the model dictionary**. This is a **huge advantage** of the **fastText** method."
      ],
      "metadata": {
        "id": "W7u3_ltK5PZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from gensim.models import FastText"
      ],
      "metadata": {
        "id": "7nbQc5uc0a1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Static variables\n",
        "TRAIN_CSV = 'https://raw.githubusercontent.com/tianqwang/Toxic-Comment-Classification-Challenge/master/data/train.csv'\n",
        "MODEL_PATH = '/content/drive/MyDrive/fastText/fast_text.model'\n",
        "IS_MODEL_SAVE = True\n",
        "IS_MODEL_LOAD = False"
      ],
      "metadata": {
        "id": "VgQUxhCFcG2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toxic_df = pd.read_csv(TRAIN_CSV, on_bad_lines='skip')\n",
        "toxic_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3YTHO-xEF04u",
        "outputId": "bfaf703f-3351-4d4d-e283-b834eda6ee34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8957b45-d2d1-4908-b333-01abcea2ab1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8957b45-d2d1-4908-b333-01abcea2ab1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8957b45-d2d1-4908-b333-01abcea2ab1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8957b45-d2d1-4908-b333-01abcea2ab1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\n",
        "    name='en', \n",
        "    disable=[\"tagger\", \"parser\", \"ner\"]\n",
        ")"
      ],
      "metadata": {
        "id": "lVubOZsoP2I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_corpus(corpus: list, batch_size: int = None) -> list:\n",
        "  global nlp\n",
        "  return [\n",
        "    [\n",
        "     token.lemma_.casefold() for token in doc \n",
        "     if token.is_alpha and not token.is_stop\n",
        "    ] for doc in nlp.pipe(texts=corpus, batch_size=batch_size)\n",
        "  ]"
      ],
      "metadata": {
        "id": "AnT8QtUnm5Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if IS_MODEL_LOAD:\n",
        "  # Load the model\n",
        "  fast_text = FastText.load(MODEL_PATH)\n",
        "  \n",
        "  # Define new corpus to re-build the vocabulary\n",
        "  corpus = []\n",
        "  \n",
        "  # Update vcabulary\n",
        "  is_update = bool(corpus)\n",
        "\n",
        "else:\n",
        "  # Initialize the model\n",
        "  fast_text = FastText(\n",
        "    size=200, # Dimensionality of the word vectors (Default 100)\n",
        "    window=3, # Sliding window size over a word (Default 5)\n",
        "    min_count=1, # Min word frequency (Default 5)\n",
        "    min_n=1, # Min length of char ngrams (Default 3)\n",
        "    max_n=5, # Max length of char ngrams (Default 6)\n",
        "    workers=4 # Number of threads to train the model  (Default 3)\n",
        "  )\n",
        "\n",
        "  # Define initial corpus to build the model on\n",
        "  corpus = toxic_df['comment_text']\n",
        "  \n",
        "  # Initiate vocabulary\n",
        "  is_update = False\n",
        "\n",
        "# Define the documents\n",
        "documents = preprocess_corpus(corpus)\n",
        "\n",
        "# Check if there are any documents\n",
        "if any(bool(doc) for doc in documents):\n",
        "  \n",
        "  # Build the vocabulary\n",
        "  fast_text.build_vocab(sentences=documents, update=is_update)\n",
        "    \n",
        "  # Train the model\n",
        "  fast_text.train(\n",
        "    sentences=documents,\n",
        "    total_examples=fast_text.corpus_count,\n",
        "    epochs=10\n",
        "  )"
      ],
      "metadata": {
        "id": "wbNJioZjckFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fast_text.wv.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afyYncwYwt5r",
        "outputId": "3dc82026-1fab-47f4-80f3-f11732c0182d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150837"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_text.wv.most_similar('eplain', topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG-cq6mw9GNX",
        "outputId": "c9e0e5ed-5f45-4e4c-db7a-39e76265ca74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('xplain', 0.8468446731567383),\n",
              " ('explain', 0.7839565873146057),\n",
              " ('eexplain', 0.7662200927734375),\n",
              " ('plain', 0.7631980180740356),\n",
              " ('reexplain', 0.7383497953414917)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained fastText model\n",
        "if IS_MODEL_SAVE:\n",
        "  fast_text.save(MODEL_PATH)"
      ],
      "metadata": {
        "id": "KiNmDBfiYUOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fastText and document distances"
      ],
      "metadata": {
        "id": "lnZIhggCA77h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Obama speaks to the media in Illinois\",\n",
        "    \"President greets the press in Chicago\",\n",
        "    \"Apple is my favorite company\"\n",
        "]"
      ],
      "metadata": {
        "id": "8aPffRmlzCfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# L2-normalized vectors\n",
        "fast_text.init_sims(replace=True)\n",
        "print('L2-normalized WMD between:')\n",
        "for i in range(len(sentences) - 1):\n",
        "  for j in range(i + 1, len(sentences)):\n",
        "    wmd = fast_text.wv.wmdistance(sentences[i], sentences[j])\n",
        "    print(' - Sentences {} and {}: {:.4f}'.format(i +1, j + 1, wmd))"
      ],
      "metadata": {
        "id": "KlLmPmhUz7BS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bec3a3-452c-4207-9cd8-b9115dd4c38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-normalized WMD between:\n",
            " - Sentences 1 and 2: 0.3505\n",
            " - Sentences 1 and 3: 0.3424\n",
            " - Sentences 2 and 3: 0.4762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "The results that we obtained in the **spelling correction** and **distance calculations** would be\n",
        " **potentially better** if **pre-trained fastText models were used** since those are mostly built on **Wikipedia text corpora** and are **more generalized** to understand **different data points**.\n",
        "\n",
        "**fastText** is a **very convenient technique** for **building word representations** using **character-level** features. It **outperformed Word2Vec** since it incorporated **internal word structure**\n",
        " information and associated it with **morphological features**, which are very important in certain languages. It also allows us to **represent words not present in the original vocabulary**. \n",
        "\n",
        "This approach based on the **character-level embedding** by incorporating **n-grams of characters** can be further **extended** to build **embeddings for documents** and **sentences** by using an approach called **Sent2Vec**.\n",
        "\n",
        "Moreover, a **Universal Sentence Encoder**,\n",
        "which is one of the **most recent algorithms** that's used to **build sentence-level embeddings** could be aplied."
      ],
      "metadata": {
        "id": "yt8iPi7P3CkB"
      }
    }
  ]
}